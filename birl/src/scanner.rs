
/// The Scanner.
///
/// A scanner is a structure responsible for scanning over some input data and
/// producing output data. It can be through of as a driver for a parser
/// combinator-like parsing solution, except for powerful in the sense that it
/// can easily handle things like iterators, in addition to the standard slice
/// data types combinators usually operate on, with no need for a distinction
/// between streaming and complete parsing.
///
/// This does come with a tradeoff, however. Where a standard parser combinator
/// can let the combinators themselves drive the consumption of data, this style
/// of parsing cannot. All consumption of data is driven by this structure. This
/// may incur increased runtime cost, depending on how complex your parse
/// functor is.
#[derive(Debug)]
pub struct Scanner<D>(D);
impl<'a> Scanner<StringDriver<'a>> {
	/// Creates a new scanner over the given source string slice.
	pub fn from_str(source: &'a str) -> Self {
		Self(StringDriver::new(source))
	}
}
impl<D> Scanner<D>
	where D: Driver {

	/// Scans over the token stream, starting at the current position of the
	/// cursor, and applies the given functor at each step to try and produce
	/// a value.
	///
	/// The semantics of this operation are very close to those of a parser
	/// combinator, except that, instead of having the functor itself drive the
	/// cursor, it has this function do it, while consulting the functor at each
	/// steep to whether the input is complete.
	pub(crate) fn scan<T, E>(
		&mut self,
		mut functor: impl FnMut(&D::Accumulator, Option<&D::Candidate>) -> ScanOp<T, E>)
		-> Option<Result<Scan<D, T>, E>> {

		loop {
			match (functor)(self.0.accumulated(), self.0.candidate()) {
				ScanOp::Continue => {
					/* The function has not made a decision yet, try again. */
					if !self.0.pull() {
						/* We can't grow our token further, seeing as we're past
						 * the end of the input string. We should bail out right
						 * away. */
						return None
					}
				},
				ScanOp::Accept(value) =>
					/* The current accumulated string has been accepted. */
					return Some(Ok(Scan {
						stream: self,
						value
					})),
				ScanOp::Reject(what) =>
					/* The current accumulated string has been rejected. */
					return Some(Err(what))
			}
		}
	}
}

/// Candidate operations to be applied during scans.
///
/// Throughout a token scan operation, it is often desirable to have more
/// than a binary acceptation or undiagnosed rejection of items. It may be
/// also be desirable for a scanning operator to give a motive for the rejection
/// of an item, as well as for it to to ask for more items before deciding.
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub enum ScanOp<T, E> {
	/// Accept the input with the given value.
	Accept(T),
	/// Reject the input as a while with the given error.
	Reject(E),
	/// Append the candidate item to the accumulated value and try again.
	Continue,
}

///
#[macro_export]
macro_rules! scan_try {
	($e:expr) => {
		match e {
			ScanOp::Continue => {},
			operation => return operation
		}
	}
}

/// The result of a scanning operation over a token stream.
#[derive(Debug)]
pub struct Scan<'a, D, T> {
	/// The underlying stream instance.
	stream: &'a mut Scanner<D>,
	/// The data value generated by the acceptation of the string.
	value: T,
}
impl<'a, D, T> Scan<'a, D, T>
	where D: Driver {

	/// The accumulate string of items that was accepted.
	pub fn string(&self) -> &D::Accumulator {
		self.stream.0.accumulated()
	}

	/// Peeks the value produced by the scanning operation.
	pub fn peek(&self) -> &T {
		&self.value
	}

	/// Discards the character string produced by this scan operation.
	pub fn rollback(self) {
		self.stream.0.rollback();
	}

	/// Consumes the selected character string scanner over by this operation
	/// and readies the scanner to take on the next token. This function also
	/// returns the value produced by the scanning operation.
	pub fn consume(self) -> T {
		self.stream.0.consume();
		self.value
	}
}

/// The interface expected of a scan driver.
pub trait Driver {
	/// The type that accumulates candidates until a parse decision is made.
	type Accumulator: ?Sized;
	/// The type that is a candidate for accumulation.
	type Candidate: ?Sized;

	/// The string of items currently in the accumulator.
	fn accumulated(&self) -> &Self::Accumulator;
	/// A reference to the next candidate.
	fn candidate(&self) -> Option<&Self::Candidate>;
	/// Pull the next candidate in the stream into the accumulator. Returns true
	/// if there is another item in the data source, false otherwise.
	fn pull(&mut self) -> bool;
	/// Consume everything in the accumulator.
	fn consume(&mut self);
	/// Rollback to the state before the last call to `consume()`.
	fn rollback(&mut self);
}

/// A scan driver iterating over characters in strings.
pub struct StringDriver<'a> {
	/// The source string we pull tokens off of.
	source: &'a str,
	/// An iterator over its characters.
	chars: std::iter::Peekable<std::str::Chars<'a>>,
	/// The candidate character.
	candidate: Option<char>,
	/// The offset to the start of the current token.
	token: usize,
	/// The current length of the token plus lookahead.
	len: usize,
	/// The current length of the token.
	acc: usize,
}
impl<'a> StringDriver<'a> {
	fn new(source: &'a str) -> Self {
		let mut chars = source.chars().peekable();
		let mut candidate = chars.peek().cloned();

		Self {
			source,
			chars,
			candidate,
			token: 0,
			len: candidate.map(|char| {
				let mut buffer = [0; 6];
				char.encode_utf8(&buffer).len()
			}).unwrap_or(0),
			acc: 0
		}
	}

	fn to_next(&self, len: usize) -> usize {
		let mut offset = 1usize;

		let check = self.token + len;
		let check = check.checked_add(offset).unwrap();
		while !self.source.is_char_boundary(check) {
			offset += 1;
		}

		offset
	}
}
impl<'a> Driver for StringDriver<'a> {
	type Accumulator = str;
	type Candidate = char;

	fn accumulated(&self) -> &Self::Accumulator {
		&self.source[self.token..self.token + self.acc]
	}
	fn candidate(&self) -> Option<&Self::Candidate> {
		self.candidate.as_ref()
	}
	fn pull(&mut self) -> bool {
		if self.acc >= self.source.len() {
			/* We can't produce any more data. */
			return false
		}

		self.len += self.to_next(self.len);
		self.acc += self.to_next(self.acc);

		let _ = self.chars.next();
		self.candidate = *self.chars.peek();

		true
	}
	fn consume(&mut self) {
		self.token += self.len;
	}
	fn rollback(&mut self) {
		self.len = 0;
	}
}

